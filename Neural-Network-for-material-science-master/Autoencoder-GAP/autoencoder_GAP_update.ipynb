{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from torch_scatter import scatter\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "pi=3.14159265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definition of Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_GAP(nn.Module):\n",
    "    def __init__(self,input_dim,GAP_2_body_dim,GAP_3_body_dim,cutoff,atom_types,\n",
    "                num_hidden_layers=3,num_hidden_dimensions=256):\n",
    "        super(Autoencoder_GAP,self).__init__()\n",
    "        self.atom_num=int(input_dim/4)\n",
    "        self.cutoff=cutoff\n",
    "        self.atom_types=atom_types\n",
    "        self.GAP_2_body_dim=GAP_2_body_dim\n",
    "        self.GAP_3_body_dim=GAP_3_body_dim\n",
    "        \n",
    "        self.GAP_2_body_k=torch.nn.Parameter(torch.rand(int(atom_types*(atom_types+1)/2),GAP_2_body_dim))\n",
    "        self.GAP_2_body_eta=torch.nn.Parameter(torch.rand(int(atom_types*(atom_types+1)/2),GAP_2_body_dim))\n",
    "        \n",
    "        '''  \n",
    "        # Comment by YY\n",
    "        self.GAP_3_body_gamma_func1=torch.nn.Parameter(torch.rand(atom_types**3,GAP_3_body_dim))\n",
    "        self.GAP_3_body_eta_func1=torch.nn.Parameter(torch.rand(atom_types**3,GAP_3_body_dim))\n",
    "        \n",
    "        self.GAP_3_body_gamma_func2=torch.nn.Parameter(torch.rand(atom_types**3,GAP_3_body_dim))\n",
    "        self.GAP_3_body_eta_func2=torch.nn.Parameter(torch.rand(atom_types**3,GAP_3_body_dim))\n",
    "                                               \n",
    "        self.GAP_3_body_gamma_func3=torch.nn.Parameter(torch.rand(atom_types**3,GAP_3_body_dim))\n",
    "        self.GAP_3_body_eta_func3=torch.nn.Parameter(torch.rand(atom_types**3,GAP_3_body_dim))\n",
    "        '''\n",
    "        self.GAP_3_body_alpha_func1=torch.nn.Parameter(torch.rand(atom_types**3,GAP_3_body_dim))\n",
    "        self.GAP_3_body_eta_func1=torch.nn.Parameter(torch.rand(atom_types**3,GAP_3_body_dim))\n",
    "        #self.GAP_3_body_beta_func1=torch.nn.Parameter(torch.rand(atom_types**3,GAP_3_body_dim))\n",
    "        self.GAP_3_body_alpha_func2=torch.nn.Parameter(torch.rand(atom_types**3,GAP_3_body_dim))\n",
    "        self.GAP_3_body_eta_func2=torch.nn.Parameter(torch.rand(atom_types**3,GAP_3_body_dim))\n",
    "        self.GAP_3_body_alpha_func3=torch.nn.Parameter(torch.rand(atom_types**3,GAP_3_body_dim))\n",
    "        self.GAP_3_body_eta_func3=torch.nn.Parameter(torch.rand(atom_types**3,GAP_3_body_dim))\n",
    "        \n",
    "        #self.decoder=nn.ModuleList([nn.Linear(GAP_2_body_dim*int(atom_types*(atom_types+1)/2)+3*GAP_3_body_dim*atom_types**3,num_hidden_dimensions),nn.ReLU()])\n",
    "        self.decoder=nn.ModuleList([nn.Linear(GAP_2_body_dim*int(atom_types*(atom_types+1)/2)+3*GAP_3_body_dim*atom_types**3,num_hidden_dimensions),nn.ReLU()])\n",
    "        for i in range(num_hidden_layers-1):\n",
    "            self.decoder.append(nn.Linear(num_hidden_dimensions,num_hidden_dimensions))\n",
    "            self.decoder.append(nn.ReLU())\n",
    "            self.decoder.append(nn.Dropout())\n",
    "                                               \n",
    "        self.decoder.append(nn.Linear(num_hidden_dimensions,input_dim))\n",
    "        self.decoder.append(nn.ReLU())\n",
    "\n",
    "    def forward(self,configs,edges_2_body,period_2_body,edges_3_body,period_3_body):\n",
    "        # calculate two-body fingerprints\n",
    "        batch_size=int(configs.shape[0]/self.atom_num)\n",
    "        vec_2_body=torch.index_select(configs[:,1:],0,edges_2_body[:,1])-\\\n",
    "                            torch.index_select(configs[:,1:],0,edges_2_body[:,2])-period_2_body #check\n",
    "        radius_2_body=torch.norm(vec_2_body,dim=1,p=2,keepdim=True)\n",
    "        fingerprint_2_body=torch.cos(torch.index_select(self.GAP_2_body_k,0,edges_2_body[:,0])*radius_2_body)*\\\n",
    "                            torch.exp(-radius_2_body/torch.index_select(self.GAP_2_body_eta,0,edges_2_body[:,0]))*\\\n",
    "                            (1+torch.cos(pi*radius_2_body/self.cutoff))/2\n",
    "        \n",
    "        # calculate three-body fingerprints\n",
    "        vec_3_body_ij=torch.index_select(configs[:,1:],0,edges_3_body[:,1])-\\\n",
    "                                torch.index_select(configs[:,1:],0,edges_3_body[:,2])-period_3_body[:,:3] #check\n",
    "        vec_3_body_ik=torch.index_select(configs[:,1:],0,edges_3_body[:,1])-\\\n",
    "                                torch.index_select(configs[:,1:],0,edges_3_body[:,3])-period_3_body[:,3:] #check\n",
    "        radius_3_body_ij=torch.norm(vec_3_body_ij,dim=1,p=2,keepdim=True)\n",
    "        radius_3_body_ik=torch.norm(vec_3_body_ik,dim=1,p=2,keepdim=True)\n",
    "        \n",
    "        \n",
    "        cos_ijk=(torch.sum(vec_3_body_ij*vec_3_body_ik,dim=1,keepdim=True)/radius_3_body_ij/radius_3_body_ik)\n",
    "        \n",
    "        '''\n",
    "        # Comment by YY\n",
    "        \n",
    "        fingerprint_3_body_func1=torch.exp(-(radius_3_body_ij**2+radius_3_body_ik**2)/(torch.index_select(self.GAP_3_body_eta_func1,0,edges_3_body[:,0])**2))*\\\n",
    "                                (1+(torch.index_select(self.GAP_3_body_gamma_func1,0,edges_3_body[:,0])*radius_3_body_ij/self.cutoff-torch.index_select(self.GAP_3_body_gamma_func1,0,edges_3_body[:,0])-1)*((radius_3_body_ij/self.cutoff)**torch.index_select(self.GAP_3_body_gamma_func1,0,edges_3_body[:,0])))*\\\n",
    "                                (1+(torch.index_select(self.GAP_3_body_gamma_func1,0,edges_3_body[:,0])*radius_3_body_ik/self.cutoff-torch.index_select(self.GAP_3_body_gamma_func1,0,edges_3_body[:,0])-1)*((radius_3_body_ik/self.cutoff)**torch.index_select(self.GAP_3_body_gamma_func1,0,edges_3_body[:,0])))*\\\n",
    "                                (cos_ijk**3)\n",
    "        fingerprint_3_body_func2=torch.exp(-(radius_3_body_ij**2+radius_3_body_ik**2)/(torch.index_select(self.GAP_3_body_eta_func2,0,edges_3_body[:,0])**2))*\\\n",
    "                                (1+(torch.index_select(self.GAP_3_body_gamma_func2,0,edges_3_body[:,0])*radius_3_body_ij/self.cutoff-torch.index_select(self.GAP_3_body_gamma_func2,0,edges_3_body[:,0])-1)*((radius_3_body_ij/self.cutoff)**torch.index_select(self.GAP_3_body_gamma_func2,0,edges_3_body[:,0])))*\\\n",
    "                                (1+(torch.index_select(self.GAP_3_body_gamma_func2,0,edges_3_body[:,0])*radius_3_body_ik/self.cutoff-torch.index_select(self.GAP_3_body_gamma_func2,0,edges_3_body[:,0])-1)*((radius_3_body_ik/self.cutoff)**torch.index_select(self.GAP_3_body_gamma_func2,0,edges_3_body[:,0])))*\\\n",
    "                                (1-4/3*cos_ijk**2)\n",
    "        fingerprint_3_body_func3=torch.exp(-(radius_3_body_ij**2+radius_3_body_ik**2)/(torch.index_select(self.GAP_3_body_eta_func3,0,edges_3_body[:,0])**2))*\\\n",
    "                                (1+(torch.index_select(self.GAP_3_body_gamma_func3,0,edges_3_body[:,0])*radius_3_body_ij/self.cutoff-torch.index_select(self.GAP_3_body_gamma_func3,0,edges_3_body[:,0])-1)*((radius_3_body_ij/self.cutoff)**torch.index_select(self.GAP_3_body_gamma_func3,0,edges_3_body[:,0])))*\\\n",
    "                                (1+(torch.index_select(self.GAP_3_body_gamma_func3,0,edges_3_body[:,0])*radius_3_body_ik/self.cutoff-torch.index_select(self.GAP_3_body_gamma_func3,0,edges_3_body[:,0])-1)*((radius_3_body_ik/self.cutoff)**torch.index_select(self.GAP_3_body_gamma_func3,0,edges_3_body[:,0])))*\\\n",
    "                                ((1-4*cos_ijk**2)*cos_ijk**2)\n",
    "        '''\n",
    "        \n",
    "        fingerprint_3_body_func1=torch.exp(-(radius_3_body_ij**2+radius_3_body_ik**2)/(torch.index_select(self.GAP_3_body_eta_func1,0,edges_3_body[:,0])**2))*\\\n",
    "                                (1+(10.0*radius_3_body_ij/self.cutoff-10.0-1.0)*((radius_3_body_ij/self.cutoff)**10.0))*\\\n",
    "                                (1+(10.0*radius_3_body_ik/self.cutoff-10.0-1.0)*((radius_3_body_ik/self.cutoff)**10.0))*\\\n",
    "                                (cos_ijk**2)*torch.index_select(self.GAP_3_body_alpha_func1,0,edges_3_body[:,0])\n",
    "        \n",
    "        fingerprint_3_body_func2=torch.exp(-(radius_3_body_ij**2+radius_3_body_ik**2)/(torch.index_select(self.GAP_3_body_eta_func2,0,edges_3_body[:,0])**2))*\\\n",
    "                                (1+(10.0*radius_3_body_ij/self.cutoff-10.0-1.0)*((radius_3_body_ij/self.cutoff)**10.0))*\\\n",
    "                                (1+(10.0*radius_3_body_ik/self.cutoff-10.0-1.0)*((radius_3_body_ik/self.cutoff)**10.0))*\\\n",
    "                                (cos_ijk**3)*torch.index_select(self.GAP_3_body_alpha_func2,0,edges_3_body[:,0])\n",
    "        \n",
    "        fingerprint_3_body_func3=torch.exp(-(radius_3_body_ij**2+radius_3_body_ik**2)/(torch.index_select(self.GAP_3_body_eta_func3,0,edges_3_body[:,0])**2))*\\\n",
    "                                (1+(10.0*radius_3_body_ij/self.cutoff-10.0-1.0)*((radius_3_body_ij/self.cutoff)**10.0))*\\\n",
    "                                (1+(10.0*radius_3_body_ik/self.cutoff-10.0-1.0)*((radius_3_body_ik/self.cutoff)**10.0))*\\\n",
    "                                (cos_ijk**4)*torch.index_select(self.GAP_3_body_alpha_func2,0,edges_3_body[:,0])\n",
    "        \n",
    "        \n",
    "        # get the final fingerprints with respect to the pair types *****\n",
    "        \n",
    "        out_2_body_fingerprint=scatter(fingerprint_2_body,edges_2_body[:,3],dim=0).reshape(batch_size,-1)\n",
    "        out_3_body_fingerprint_1=scatter(fingerprint_3_body_func1,edges_3_body[:,4],dim=0).reshape(batch_size,-1)\n",
    "        out_3_body_fingerprint_2=scatter(fingerprint_3_body_func2,edges_3_body[:,4],dim=0).reshape(batch_size,-1)\n",
    "        out_3_body_fingerprint_3=scatter(fingerprint_3_body_func3,edges_3_body[:,4],dim=0).reshape(batch_size,-1)\n",
    "        x=torch.cat((out_2_body_fingerprint,out_3_body_fingerprint_1,out_3_body_fingerprint_2,out_3_body_fingerprint_3),dim=1)\n",
    "\n",
    "#         The following is another version to aggregate the fingerprint of the mini-batch\n",
    "#         final_fingerprint=list()\n",
    "#         for batch_num in range(batch_size):\n",
    "#             for i in range(int(self.atom_types*(self.atom_types+1)/2)):\n",
    "#                 mask=((edges_2_body[:,0]==i) & (edges_2_body[:,3]==batch_num)).reshape(-1,1)  \n",
    "#                 final_fingerprint.append(torch.sum(torch.masked_select(fingerprint_2_body,mask).reshape(-1,self.GAP_2_body_dim),dim=0))\n",
    "#             for i in range(self.atom_types**3):\n",
    "#                 mask=((edges_3_body[:,0]==i) & (edges_3_body[:,4]==batch_num)).reshape(-1,1)\n",
    "#                 final_fingerprint.append(torch.sum(torch.masked_select(fingerprint_3_body_func1,mask).reshape(-1,self.GAP_3_body_dim),dim=0))\n",
    "\n",
    "#                 #Comment by YY\n",
    "#                 final_fingerprint.append(torch.sum(torch.masked_select(fingerprint_3_body_func2,mask).reshape(-1,self.GAP_3_body_dim),dim=0))\n",
    "#                 final_fingerprint.append(torch.sum(torch.masked_select(fingerprint_3_body_func3,mask).reshape(-1,self.GAP_3_body_dim),dim=0))\n",
    "            \n",
    "#         x=torch.cat(final_fingerprint).reshape(batch_size,-1)\n",
    "        \n",
    "        # use fingerprints to decode atomic configurations\n",
    "        for model in self.decoder:\n",
    "            x=model(x)\n",
    "        return x.reshape(-1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIDDEN_LAYERS=3\n",
    "NUM_HIDDEN_DIMENSIONS=512  # what is meanning of 512??\n",
    "LEARNING_RATE_INIT=0.001\n",
    "ATOM_TYPES=2\n",
    "use_device='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definition of dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAP_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,datafile,begin,end):\n",
    "        super(GAP_dataset,self).__init__()\n",
    "        self.datafile=datafile\n",
    "        self.begin=begin # include in the dataset\n",
    "        self.end=end # exclude in the dataset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.end-self.begin\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        name=str((index+self.begin)*1)\n",
    "        config=np.loadtxt(self.datafile+'AtomicInfo-'+name+'.txt')\n",
    "        info_2_body=np.loadtxt(self.datafile+'PairInfo-'+name+'.txt')\n",
    "        info_3_body=np.loadtxt(self.datafile+'3BodyInfo-'+name+'.txt')\n",
    "        return torch.tensor(config,dtype=torch.float),\\\n",
    "                torch.tensor(info_2_body[:,:3],dtype=torch.int64),\\\n",
    "                torch.tensor(info_2_body[:,3:],dtype=torch.float),\\\n",
    "                torch.tensor(info_3_body[:,:4],dtype=torch.int64),\\\n",
    "                torch.tensor(info_3_body[:,4:],dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(x):\n",
    "    config,pair_2_body,period_2_body,pair_3_body,period_3_body=zip(*x)\n",
    "    atom_num=config[0].shape[0]\n",
    "    batch_size=len(config)\n",
    "    \n",
    "    config=torch.cat(config)\n",
    "    \n",
    "    temp_list=list()\n",
    "    for i in range(batch_size):\n",
    "        pair_2_body[i][:,1:3]+=(atom_num*i)\n",
    "        #temp_list.append(torch.full((pair_2_body[i].shape[0],1),i,dtype=torch.int64))\n",
    "        temp_list.append(torch.full((pair_2_body[i].shape[0],1),i*int(ATOM_TYPES*(ATOM_TYPES+1)/2),dtype=torch.int64))\n",
    "    temp_list=torch.cat(temp_list).reshape(-1,1)\n",
    "    pair_2_body=torch.cat(pair_2_body)\n",
    "    pair_2_body=torch.cat((pair_2_body,temp_list+pair_2_body[:,0].reshape(-1,1)),dim=1)\n",
    "    \n",
    "    period_2_body=torch.cat(period_2_body)\n",
    "    \n",
    "    temp_list=list()\n",
    "    for i in range(batch_size):\n",
    "        pair_3_body[i][:,1:4]+=(atom_num*i)\n",
    "        #temp_list.append(torch.full((pair_3_body[i].shape[0],1),i,dtype=torch.int64))\n",
    "        temp_list.append(torch.full((pair_3_body[i].shape[0],1),i*ATOM_TYPES**3,dtype=torch.int64))\n",
    "    temp_list=torch.cat(temp_list).reshape(-1,1)\n",
    "    pair_3_body=torch.cat(pair_3_body)\n",
    "    pair_3_body=torch.cat((pair_3_body,temp_list+pair_3_body[:,0].reshape(-1,1)),dim=1)\n",
    "    \n",
    "    period_3_body=torch.cat(period_3_body)\n",
    "    \n",
    "    return config,pair_2_body,period_2_body,pair_3_body,period_3_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pin_memory=False # if the RAM capacity is large enough, set this as True can accelerate training process\n",
    "\n",
    "train_size=50\n",
    "valid_size=25\n",
    "test_size=25\n",
    "\n",
    "train_dataset=GAP_dataset('./test-data-all/',0,50)\n",
    "valid_dataset=GAP_dataset('./test-data-all/',50,75)\n",
    "test_dataset=GAP_dataset('./test-data-all/',75,100)\n",
    "\n",
    "train_dataloader=DataLoader(train_dataset,pin_memory=is_pin_memory,collate_fn=custom_collate_fn,batch_size=10) \n",
    "valid_dataloader=DataLoader(valid_dataset,pin_memory=is_pin_memory,collate_fn=custom_collate_fn,batch_size=10)\n",
    "test_dataloader=DataLoader(test_dataset,pin_memory=is_pin_memory,collate_fn=custom_collate_fn,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Autoencoder_GAP(input_dim=64*4,GAP_2_body_dim=8,GAP_3_body_dim=4,cutoff=5.5,atom_types=2,       #Comment by YY\n",
    "#                     num_hidden_layers=NUM_HIDDEN_LAYERS,num_hidden_dimensions=NUM_HIDDEN_DIMENSIONS)  #Comment by YY\n",
    "model=Autoencoder_GAP(input_dim=64*4,GAP_2_body_dim=8,GAP_3_body_dim=4,cutoff=5.5,atom_types=ATOM_TYPES,\n",
    "                     num_hidden_layers=NUM_HIDDEN_LAYERS,num_hidden_dimensions=NUM_HIDDEN_DIMENSIONS)\n",
    "\n",
    "model.to(use_device)\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=LEARNING_RATE_INIT)\n",
    "scheduler=torch.optim.lr_scheduler.StepLR(optimizer,step_size=5,gamma=0.8)   ### what is the meaning of this line???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  training error =  14747.8421875  validation error =  14038.218125  training and validation time =  0:00:15.275596\n",
      "Epoch  1  training error =  12332.53484375  validation error =  8541.218125  training and validation time =  0:00:14.778505\n",
      "Epoch  2  training error =  5385.413125  validation error =  3039.0363671875  training and validation time =  0:00:14.786486\n",
      "Epoch  3  training error =  3003.281171875  validation error =  795.17173828125  training and validation time =  0:00:15.085688\n",
      "Epoch  4  training error =  1271.6692578125  validation error =  1201.9875  training and validation time =  0:00:15.421788\n",
      "Epoch  5  training error =  1466.978203125  validation error =  821.101240234375  training and validation time =  0:00:15.547452\n",
      "Epoch  6  training error =  1328.0790234375  validation error =  690.47134765625  training and validation time =  0:00:15.665138\n",
      "Epoch  7  training error =  1100.10755859375  validation error =  564.713994140625  training and validation time =  0:00:16.522845\n",
      "Epoch  8  training error =  950.5565625  validation error =  539.087470703125  training and validation time =  0:00:16.273511\n",
      "Epoch  9  training error =  959.608984375  validation error =  542.6656591796875  training and validation time =  0:00:16.399176\n",
      "Epoch  10  training error =  963.19322265625  validation error =  586.339970703125  training and validation time =  0:00:16.232622\n",
      "Epoch  11  training error =  887.801767578125  validation error =  548.3907421875  training and validation time =  0:00:16.399176\n",
      "Epoch  12  training error =  887.268916015625  validation error =  511.1326416015625  training and validation time =  0:00:16.349310\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# how to load a model as the intial point of the NN model\n",
    "model=torch.load('best_model.pkl')\n",
    "model=final_model.to(use_device)\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=LEARNING_RATE_INIT)\n",
    "scheduler=torch.optim.lr_scheduler.StepLR(optimizer,step_size=5,gamma=0.8)   ### what is the meaning of this line???\n",
    "'''\n",
    "min_valid_error=np.inf\n",
    "train_errors=list()\n",
    "valid_errors=list()\n",
    "cnt=0\n",
    "for i in range(200):\n",
    "    time_beg_epoch=datetime.datetime.now()\n",
    "\n",
    "    #training process\n",
    "    model.train()\n",
    "    train_error=0\n",
    "    for config,info_2_body_list,info_2_body_period,info_3_body_list,info_3_body_period in train_dataloader:\n",
    "        config=config.to(use_device)\n",
    "        info_2_body_list=info_2_body_list.to(use_device)\n",
    "        info_2_body_period=info_2_body_period.to(use_device)\n",
    "        info_3_body_list=info_3_body_list.to(use_device)\n",
    "        info_3_body_period=info_3_body_period.to(use_device)\n",
    "        optimizer.zero_grad()   ##????\n",
    "        reconstruct_val=model(config,info_2_body_list,info_2_body_period,info_3_body_list,info_3_body_period)  ###????\n",
    "        loss=torch.nn.functional.mse_loss(reconstruct_val,config,reduction='sum')\n",
    "        loss.backward(torch.ones_like(loss))\n",
    "        optimizer.step() ###???\n",
    "        train_error+=torch.sum(loss).cpu().detach().numpy()\n",
    "    train_errors.append(train_error/train_size)\n",
    "\n",
    "    #validation process\n",
    "    model.eval()\n",
    "    valid_error=0\n",
    "    for config,info_2_body_list,info_2_body_period,info_3_body_list,info_3_body_period in valid_dataloader:\n",
    "        config=config.to(use_device)\n",
    "        info_2_body_list=info_2_body_list.to(use_device)\n",
    "        info_2_body_period=info_2_body_period.to(use_device)\n",
    "        info_3_body_list=info_3_body_list.to(use_device)\n",
    "        info_3_body_period=info_3_body_period.to(use_device)\n",
    "        reconstruct_val=model(config,info_2_body_list,info_2_body_period,info_3_body_list,info_3_body_period)\n",
    "        loss=torch.nn.functional.mse_loss(reconstruct_val,config,reduction='sum')\n",
    "        valid_error+=torch.sum(loss).cpu().detach().numpy()\n",
    "    valid_errors.append(valid_error/valid_size)\n",
    "\n",
    "    #print information & judgement for early stopping\n",
    "    scheduler.step()\n",
    "    time_end_epoch=datetime.datetime.now()\n",
    "    print('Epoch ',i,' training error = ',train_error/train_size,\n",
    "          ' validation error = ',valid_error/valid_size,\n",
    "          ' training and validation time = ',time_end_epoch-time_beg_epoch)\n",
    "\n",
    "    if valid_error<min_valid_error: #judgement for early stopping\n",
    "        cnt=0\n",
    "        torch.save(model,'best_model.pkl')\n",
    "        min_valid_error=valid_error\n",
    "    else:\n",
    "        cnt+=1\n",
    "        if cnt>=10:\n",
    "            print('Early stopping')\n",
    "            del(model)\n",
    "            with open('training_errors.pickle','wb') as f:\n",
    "                pickle.dump(train_errors,f)\n",
    "            with open('valid_errors.pickle','wb') as f:\n",
    "                pickle.dump(valid_errors,f)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=torch.load('best_model.pkl')\n",
    "final_model=final_model.to(use_device)\n",
    "final_model.eval()\n",
    "reconstructions=list()\n",
    "true_configs=list()\n",
    "test_error=0\n",
    "for config,info_2_body_list,info_2_body_period,info_3_body_list,info_3_body_period in test_dataloader:\n",
    "    config=config.to(use_device)\n",
    "    info_2_body_list=info_2_body_list.to(use_device)\n",
    "    info_2_body_period=info_2_body_period.to(use_device)\n",
    "    info_3_body_list=info_3_body_list.to(use_device)\n",
    "    info_3_body_period=info_3_body_period.to(use_device)\n",
    "    pred_reconstruct=final_model(config,info_2_body_list,info_2_body_period,info_3_body_list,info_3_body_period)\n",
    "    reconstructions.append(pred_reconstruct.cpu().detach().numpy())\n",
    "    true_configs.append(config.cpu().detach().numpy())\n",
    "    loss=torch.nn.functional.mse_loss(pred_reconstruct,config,reduction='sum')\n",
    "    test_error+=torch.sum(loss).cpu().detach().numpy()\n",
    "print(test_error/test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_configs[0]-reconstructions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(reconstructions[0])\n",
    "#reconstructions[995]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(true_configs[0])\n",
    "#true_configs-reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_model.GAP_2_body_eta)\n",
    "eta_2 = final_model.GAP_2_body_eta.cpu().detach().numpy()\n",
    "eta_2\n",
    "eta_2.reshape(-1,1)\n",
    "np.shape(eta_2.reshape(-1,1))\n",
    "np.savetxt(\"Para-eta2.txt\",eta_2.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_model.GAP_2_body_k)\n",
    "k_2 = final_model.GAP_2_body_k.cpu().detach().numpy().reshape(-1,1)\n",
    "np.shape(k_2)\n",
    "np.savetxt(\"Para-k2.txt\",k_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_model.GAP_3_body_eta_func1)\n",
    "eta_3_1 = final_model.GAP_3_body_eta_func1.cpu().detach().numpy().reshape(-1,1)\n",
    "np.shape(eta_3_1)\n",
    "np.savetxt(\"Para-eta3_1.txt\",eta_3_1)\n",
    "\n",
    "alpha_3_1 = final_model.GAP_3_body_alpha_func1.cpu().detach().numpy().reshape(-1,1)\n",
    "np.shape(alpha_3_1)\n",
    "np.savetxt(\"Para-alpha3_1.txt\",alpha_3_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_model.GAP_3_body_alpha_func1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_model.GAP_3_body_eta_func2)\n",
    "eta_3_2 = final_model.GAP_3_body_eta_func2.cpu().detach().numpy().reshape(-1,1)\n",
    "np.shape(eta_3_2)\n",
    "np.savetxt(\"Para-eta3_2.txt\",eta_3_2)\n",
    "\n",
    "alpha_3_2 = final_model.GAP_3_body_alpha_func2.cpu().detach().numpy().reshape(-1,1)\n",
    "np.shape(alpha_3_2)\n",
    "np.savetxt(\"Para-alpha3_2.txt\",alpha_3_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_model.GAP_3_body_eta_func3)\n",
    "eta_3_3 = final_model.GAP_3_body_eta_func3.cpu().detach().numpy().reshape(-1,1)\n",
    "np.shape(eta_3_3)\n",
    "np.savetxt(\"Para-eta3_3.txt\",eta_3_3)\n",
    "\n",
    "alpha_3_3 = final_model.GAP_3_body_alpha_func3.cpu().detach().numpy().reshape(-1,1)\n",
    "np.shape(alpha_3_3)\n",
    "np.savetxt(\"Para-alpha3_3.txt\",alpha_3_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
